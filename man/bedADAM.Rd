% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradient.R
\name{bedADAM}
\alias{bedADAM}
\title{Use the ADAM optimiser to learn a linear regression model from plink data}
\usage{
bedADAM(
  bed,
  y,
  maxIter = 1000,
  p = list(),
  ssize = 100,
  seed = NULL,
  iterskip = 10,
  verbose = TRUE
)
}
\arguments{
\item{bed}{A \code{rbed} object as returned by \code{\link[pcapred]{readbed}}, or a \code{mergedrbed} object as returned by \code{\link[pcapred]{mergeref}}.}

\item{y}{A vector of length bed$no.ind, giving the predicted value}

\item{maxIter}{(default=1000) maximum number of iterations to run the optimiser for}

\item{p}{(default =list()) a vector specifying any control parameters to be set manually; these are described above.}

\item{ssize}{(default=100) Number of 4-individual binary chunks to use per stochastic update; this is the "minibatch" size.}

\item{seed}{(default=NULL) Optional seed setting}

\item{iterskip}{(dfefault=10) If verbose, print to screen only on every iterskip iteration.}

\item{verbose}{(default=TRUE) whether to display iteration progress}
}
\value{
A list containing:
\itemize{
\item loss: The history of the average loss (length maxIter), on the subset of data it was calculated on
\item change: The history of change size (length maxIter), i.e.  the RMS of the step sizes
\item theta: The current best estimate of \eqn{\beta}.
\item p: The previous parameter estimate.
}
}
\description{
For \eqn{y = \beta X + \epsilon}, use the ADAM optimiser to minimise
\deqn{|\epsilon|^2_2= \sum{i=1}^N (y_i - \sum_{j=1}^L \beta_{j} X_{ij})^2.}
The ADAM optimiser is an ADAptive Maximiser similar in spirit to Stochastic Gradient Descent. This allows linear regression to be applied to very large problems for which exact solutions are impossible.

The components of this model are (p below):
\itemize{
\item theta (if missing, generate randomly using \code{\link{initTheta}}) our estimate of \eqn{\beta} of length L.
\item alpha (default 0.1) The "learning rate"
\item beta1 (default 0.9) A component of ADAM
\item beta1 (default 0.999) A component of ADAM
\item meanMoment (default a vector of 0 with length L) The current momentum for each variable
\item varianceMoment (default a vector of 0 with length L) The current momentum for each variables variance
\item smooth (default 1e-7) A regularisation on the variance estimate
}
}
